{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing_Data_Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project :\n",
    "The task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in the range as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year as described above, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "\n",
    "You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'data/autos1.csv'\n",
    "OUTPUT_GOOD = 'data/autos-valid.csv'\n",
    "OUTPUT_BAD = 'data/autos-Fixme.csv'\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "def process_file(input_file, output_good, output_bad):\n",
    "    # store data into lists for output\n",
    "    data_good = []\n",
    "    data_bad = []\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        for row in reader:\n",
    "            # validate URI value\n",
    "            if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "                continue\n",
    "\n",
    "            ps_year = row['productionStartYear'][:4]\n",
    "            try: # use try/except to filter valid items\n",
    "                ps_year = int(ps_year)\n",
    "                row['productionStartYear'] = ps_year\n",
    "                if (ps_year >= 1886) and (ps_year <= 2014):\n",
    "                    data_good.append(row)\n",
    "                else:\n",
    "                    data_bad.append(row)\n",
    "            except ValueError: # non-numeric strings caught by exception\n",
    "                if ps_year == 'NULL':\n",
    "                    data_bad.append(row)\n",
    "\n",
    "    # Write processed data to output files\n",
    "    with open(output_good, \"w\", encoding=\"utf-8\") as good:\n",
    "        writer = csv.DictWriter(good, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_good:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    with open(output_bad, \"w\", encoding=\"utf-8\") as bad:\n",
    "        writer = csv.DictWriter(bad, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_bad:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "\n",
    "def test():\n",
    "\n",
    "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project :\n",
    "\n",
    "In this problem set we work with cities infobox data, audit it, come up with a cleaning idea and then clean it up.\n",
    "In the first exercise we want you to audit the datatypes that can be found in some particular fields in the dataset.\n",
    "The possible types of values can be:\n",
    "- 'NoneType' if the value is a string \"NULL\" or an empty string \"\"\n",
    "- 'list', if the value starts with \"{\"\n",
    "- 'int', if the value can be cast to int\n",
    "- 'float', if the value can be cast to float, but is not an int\n",
    "- 'str', for all other values\n",
    "\n",
    "The audit_file function should return a dictionary containing fieldnames and the datatypes that can be found in the field.\n",
    "All the data initially is a string, so you have to do some checks on the values first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'areaCode': {<class 'int'>, <class 'NoneType'>, <class 'str'>},\n",
      " 'areaLand': {<class 'list'>, <class 'NoneType'>, <class 'float'>},\n",
      " 'areaMetro': {<class 'NoneType'>, <class 'float'>},\n",
      " 'areaUrban': {<class 'NoneType'>, <class 'float'>},\n",
      " 'elevation': {<class 'list'>, <class 'NoneType'>, <class 'float'>},\n",
      " 'governmentType_label': {<class 'NoneType'>, <class 'str'>},\n",
      " 'homepage': {<class 'NoneType'>, <class 'str'>},\n",
      " 'isPartOf_label': {<class 'list'>, <class 'str'>, <class 'NoneType'>},\n",
      " 'maximumElevation': {<class 'NoneType'>},\n",
      " 'minimumElevation': {<class 'NoneType'>},\n",
      " 'name': {<class 'list'>, <class 'str'>, <class 'NoneType'>},\n",
      " 'populationDensity': {<class 'list'>, <class 'NoneType'>, <class 'float'>},\n",
      " 'populationTotal': {<class 'int'>, <class 'NoneType'>},\n",
      " 'timeZone_label': {<class 'str'>, <class 'NoneType'>},\n",
      " 'utcOffset': {<class 'list'>,\n",
      "               <class 'int'>,\n",
      "               <class 'NoneType'>,\n",
      "               <class 'str'>},\n",
      " 'wgs84_pos#lat': {<class 'float'>},\n",
      " 'wgs84_pos#long': {<class 'float'>}}\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "CITIES = 'data/cities.csv'\n",
    "\n",
    "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\", \"isPartOf_label\", \"areaCode\", \"populationTotal\", \n",
    "          \"elevation\", \"maximumElevation\", \"minimumElevation\", \"populationDensity\", \"wgs84_pos#lat\", \"wgs84_pos#long\", \n",
    "          \"areaLand\", \"areaMetro\", \"areaUrban\"]\n",
    "\n",
    "def is_int(value):\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def is_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def audit_file(filename, fields):\n",
    "    fieldtypes = {}\n",
    "\n",
    "    for field in fields:\n",
    "        fieldtypes[field] = set()\n",
    "\n",
    "    with open(filename, 'r') as input:\n",
    "        reader = csv.DictReader(input)\n",
    "\n",
    "        for row in reader:\n",
    "            if row['URI'].find('dbpedia') > -1:\n",
    "                \n",
    "                for field in fields:\n",
    "\n",
    "                    if row[field] == \"NULL\" or row[field] == \"\":\n",
    "                        fieldtypes[field].add(type(None))\n",
    "                    elif row[field][0] == \"{\":\n",
    "                        fieldtypes[field].add(type([]))\n",
    "                    elif is_int(row[field]):\n",
    "                        fieldtypes[field].add(type(1))    \n",
    "                    elif is_float(row[field]):\n",
    "                        fieldtypes[field].add(type(1.1))\n",
    "                    else:\n",
    "                        fieldtypes[field].add(type(''))  \n",
    "\n",
    "    return fieldtypes\n",
    "\n",
    "\n",
    "def test():\n",
    "    fieldtypes = audit_file(CITIES, FIELDS)\n",
    "\n",
    "    pprint.pprint(fieldtypes)\n",
    "    \n",
    "    assert fieldtypes[\"areaLand\"] == set([type(1.1), type([]), type(None)])\n",
    "    assert fieldtypes['areaMetro'] == set([type(1.1), type(None)])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
